{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hidden_Markov_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-6WzIEAFRRZ"
      },
      "source": [
        "# Hidden Markov Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6-omD76pFgw"
      },
      "source": [
        "In this project, I have taken shakespeare plays dataset and built a Hidden Markov Model such that it can generate new text as well as predict the lines based on the words given. This project's main purpose is to understand how we can generate new text and predict the sequence of words within the dataset provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lQ-k1FYpFk9"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3CPWTXVFSdc"
      },
      "source": [
        "#Importing required libraries\n",
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-jnl1fKpYGX"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZb1qBWfFSlY"
      },
      "source": [
        "#Importing the data\n",
        "text_data = 'alllines.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxz8M8B6pfbC"
      },
      "source": [
        "## Functions to create dictionaries and probability calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoU8vdEVFSoK"
      },
      "source": [
        "#Removing trailing characters like commas, punctuations  \n",
        "def clean(line):\n",
        "    return line.translate(str.maketrans('','', string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF3LHeQ_FSrI"
      },
      "source": [
        "#Creating dictionaries\n",
        "def create_dictionary(dic, key, value):\n",
        "    if key not in dic:\n",
        "        dic[key] = []\n",
        "    dic[key].append(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o1avYNcFStq"
      },
      "source": [
        "#Probability calculations\n",
        "def create_probability_dictionary(list):\n",
        "    probability_dictionary = {}\n",
        "    list_length = len(list)\n",
        "    for item in list:\n",
        "        probability_dictionary[item] = probability_dictionary.get(item, 0) + 1\n",
        "    for key, value in probability_dictionary.items():\n",
        "        probability_dictionary[key] = value / list_length\n",
        "    return probability_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urMrn8S7pyxP"
      },
      "source": [
        "## Implementation of HMM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvGuvhl8tUgI"
      },
      "source": [
        "In Hidden Markov Model, we have invisible Markov chain, markov chain is nothing but graphs with transitional probabilities. Here, the probability of being in one state depends only on the previous state irrespective of the transitions happened previously. \n",
        "\n",
        "Following are the steps used when implementing this model:\n",
        "1. Cleaning the text data\n",
        "2. Building state-pairs\n",
        "3. Calculating probability Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyM6uioCFSy1"
      },
      "source": [
        "#Required variables to hold the initial state and transition states\n",
        "firstWord = {}\n",
        "secondWord = {}\n",
        "transitions = {}\n",
        "#Hidden Markov Model Implementation\n",
        "def hidden_markov_model():\n",
        "    for each_line in open(text_data):\n",
        "        \n",
        "        #Tokenization using rstrip to get stripped sentences by removing trailing characters.\n",
        "        token = clean(each_line.rstrip().lower()).split()\n",
        "        token_length = len(token)\n",
        "        \n",
        "        #Creating state pairs\n",
        "        for i in range(token_length):\n",
        "            current_token = token[i]\n",
        "            \n",
        "            #Initial state distribution calculations required for firstWord\n",
        "            if i == 0:\n",
        "                firstWord[current_token] = firstWord.get(current_token, 0) + 1\n",
        "            else:\n",
        "                previous_token = token[i - 1]\n",
        "                \n",
        "                #Creating additional identification token for lastWord\n",
        "                if i == token_length - 1:\n",
        "                    create_dictionary(transitions, (previous_token, current_token), 'END')\n",
        "                \n",
        "                #The flow will be continued with the secondWord considering as first level markov model\n",
        "                if i == 1:\n",
        "                    create_dictionary(secondWord, previous_token, current_token)\n",
        "                else:\n",
        "                    prev2prev_token = token[i - 2]\n",
        "                    create_dictionary(transitions, (prev2prev_token, previous_token), current_token)\n",
        "                    \n",
        "    #Probability Distributions\n",
        "    first_count = sum(firstWord.values())\n",
        "    for key, value in firstWord.items():\n",
        "        firstWord[key] = value / first_count\n",
        "        \n",
        "    for previous, next_list in secondWord.items():\n",
        "        secondWord[previous] = create_probability_dictionary(next_list)\n",
        "        \n",
        "    for word_pair, next_list in transitions.items():\n",
        "        transitions[word_pair] = create_probability_dictionary(next_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTvrLWwzFS1P"
      },
      "source": [
        "#Calling the function\n",
        "hidden_markov_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR7nHy5dFS4A"
      },
      "source": [
        "#Function for sample word\n",
        "def sample_word(dict):\n",
        "    random_number = np.random.random()\n",
        "    total = 0\n",
        "    for key, value in dict.items():\n",
        "        total += value\n",
        "        if random_number < total:\n",
        "            return key\n",
        "    assert(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8lcB18Bp-O-"
      },
      "source": [
        "## Function to generate new text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0g4wu-6FS9A"
      },
      "source": [
        "#Generated text length\n",
        "new_text_length = 7\n",
        "# Function to generate new text\n",
        "def new_text():\n",
        "    for i in range(new_text_length):\n",
        "        list = []\n",
        "        \n",
        "        # First Word\n",
        "        fword = sample_word(firstWord)\n",
        "        list.append(fword)\n",
        "        # Second word\n",
        "        sword = sample_word(secondWord[fword])\n",
        "        list.append(sword)\n",
        "        \n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            tword = sample_word(transitions[(fword, sword)])\n",
        "            if tword == 'END':\n",
        "                break\n",
        "            list.append(tword)\n",
        "            fword = sword\n",
        "            sword = tword\n",
        "        print(' '.join(list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNGS3kDzFS_h",
        "outputId": "196f76ab-016b-4273-e076-63d075646203"
      },
      "source": [
        "#New text generation\n",
        "new_text()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "too loud or tainting his discipline or from what cause have i not lie\n",
            "need to beg relief among romes enemies\n",
            "she will take the praise\n",
            "and to him\n",
            "you must forget to pity me\n",
            "and shalt be loggerhead good faith tis day\n",
            "why he a prince deserves it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUTwWJsau3IZ"
      },
      "source": [
        "## Observation:\n",
        "\n",
        "Here, from above result we can observe that, the new text is generated but it doesn't have any meaning to it. It is mainly because HMM doesn't hold the memory resulting in text with sequence of words without any actual meaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpO6vle3qB4G"
      },
      "source": [
        "## Function to predict the line based on words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7WfB5J2FTB-"
      },
      "source": [
        "#Function to predict the line based on words\n",
        "def text_guesser(lines):\n",
        "        lines = clean(lines.rstrip().lower()).split()\n",
        "        fword = lines[0]\n",
        "        if len(lines) == 1:\n",
        "            sword = [max(self.second_word(fword), key=second_word(fword).get)]\n",
        "            lines.append(sword)\n",
        "        else:\n",
        "            sword = lines[1]\n",
        "        while True:\n",
        "            tword = max(transitions[(fword, sword)], key=transitions[(fword, sword)].get)\n",
        "            if tword == 'END':\n",
        "                break\n",
        "            lines.append(tword)\n",
        "            fword = sword\n",
        "            sword = tword\n",
        "        print(' '.join(lines) + '.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNCK8oPNFTEg",
        "outputId": "dbd629de-8448-413a-b85d-a4bd0da5ea61"
      },
      "source": [
        "text_guesser(\"most resolutely\")\n",
        "text_guesser(\"dissolutely spent\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "most resolutely snatched on monday night and day.\n",
            "dissolutely spent on tuesday morning got with.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xmbfHSWvTX9"
      },
      "source": [
        "## Observation:\n",
        "\n",
        "From the above prediction, we can say that HMM performed pretty well in predicting the lines when given sequence of words. If the words are unique in the dataset, you get an exact line from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLBGi2MKqK5P"
      },
      "source": [
        "## Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MrSnKTrqN1h"
      },
      "source": [
        "From the above results, we can say that Hidden Markov Model works pretty well in generating new text and predicting the lines when given a sequence of words."
      ]
    }
  ]
}